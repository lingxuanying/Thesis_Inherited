# -*- coding: utf-8 -*-
"""trainning_data_for_fall40.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A7nFBGW5aPqYmTuQmcqDT29QGD9RceIz
"""


import pandas as pd
import numpy as np
import random
import sys

pd.set_option('display.max_columns', None)

criteria = sys.argv[1] # 90/40/MAP
split_patient = sys.argv[2] # 0/1 有無重新分配Train / Validation / Test病患
split_data = sys.argv[3] # 0/1 有無重新分配Train / Validation / Test透析資料
data_file = sys.argv[5]
patient_id_path = sys.argv[6]
data_row_index_path = sys.argv[7]
pickle_path = sys.argv[8]

print('Generate Pickle...')

file_name = data_file #'/content/drive/My Drive/IDH_Thesis/20220905新版資料/Training_data_篩過的.csv'
data = pd.read_csv(file_name, encoding='utf-8', engine='python')

data['start-time'] = pd.to_datetime(data['start-time'])
data['start-analysis-date'] = pd.to_datetime(data['start-analysis-date'])
data['UF'] = pd.to_numeric(data['UF'],errors='coerce')
data = data.replace('None',np.nan)
data['SP-start'] = pd.to_numeric(data['SP-start'], errors='coerce')
data['SP-end'] = pd.to_numeric(data['SP-end'], errors='coerce')

sample_num = 5
sequential = ['SP-start', 'DP-start', 'Dialysis-blood-rate', 'Dehydration-rate', 'HR', 'RR', 'blood-speed', 'normal_saline', 'Dialysis-blood-temp']
#sequential = ['SP-start', 'UF', 'Age']
non_sequential = ['start-weight', 'predict-Dehydration', 'Sum_HTN_Drugs', 'DM', 'HTN', 'CAD', 'Age', 'Sex', 'frequency_'+criteria, 'Hb', 'Hct', 'MCV', 'RBC', 'WBC', 'Plt', 'CREA', 'eGFR', 'NA',
          'K', 'CA', 'P', 'CO2', 'URIC', 'BUN_前', 'BUN_後', 'Ferritin', 'TIBC', 'IRON', 'PTHi.', '8202CRP', 'HbA1C', 'LDL-C', 'CHOL', 'TRIG', '8203CRP']

temperature = []
for i in range(24, 48):
  temperature.append('temperature' + str(i))
train_size = 0.8
valid_size = 0.1
test_size = 0.1

def normalize(data):
  df = pd.DataFrame(data) 
  x = df.values #returns a numpy array
  min_max_scaler = preprocessing.MinMaxScaler()
  x_scaled = min_max_scaler.fit_transform(x)
  df = pd.DataFrame(x_scaled)
  temperature_list = df.values
  return temperature_list

from sklearn import preprocessing

for i in sequential:
  data[i] = pd.to_numeric(data[i],errors='coerce')
  #data[i] = normalize(data[i]) # 對feature整欄做normalize

for i in non_sequential:
  data[i] = pd.to_numeric(data[i],errors='coerce')
  #data[i] = normalize(data[i])

for i in temperature:
  data[i] = pd.to_numeric(data[i],errors='coerce')

#temp_data[temperature] = temp_data[temperature].apply(lambda x: (x - x.min()) / (x.max() - x.min())) #對
#data['time_step'] = normalize(data['time_step'])

data = data.fillna(-1)
"""# Train, Valid, Test"""

if(split_patient):
  patient_list = list(pd.unique(data['ID']))
  train_PatientID = random.sample(patient_list, k=round(len(patient_list) * train_size))
  test_PatientID = list(set(patient_list) - set(train_PatientID))
  valid_PatientID = random.sample(test_PatientID, k=round(len(test_PatientID) * (valid_size / (valid_size + test_size))))
  test_PatientID = list(set(patient_list) - set(train_PatientID) - set(valid_PatientID))

  # record the patient_id
  path = patient_id_path
  f = open(path, 'w')
  f.write('train_PatientID = ')
  f.write(str(train_PatientID))
  f.write('\n')

  f.write('valid_PatientID = ')
  f.write(str(valid_PatientID))
  f.write('\n')

  f.write('test_PatientID = ')
  f.write(str(test_PatientID))
  f.write('\n')
  f.close()

"""# 從 Patient_ID.txt 直接讀 Train, Valid, Test"""

if(split_patient==0):
  f = open(patient_id_path, "r")
  text = f.readlines()
  for i in range(3):
    info = str(text[i]).strip("\n").strip("'")
    exec(info)

"""# 選擇透析資料(Train)"""

def get_data(data):
  PatientID = data['ID'][0]
  positive = [] # 其中一次紀錄label = True的透析
  negative = [] # 沒有任何紀錄label = True的透析
  s_list = [[0, data['label_'+criteria][0]]] # 紀錄透析中每次紀錄的index與label，用來決定該次透析屬於positive / negative
  start_dialysis = data['start-analysis-date'][0] #決定該次透析是否已取完紀錄

  training_list = []
  unbalanced_training_list = []

  for i in range(len(data)):
    # 同一個病人
    if(data['ID'][i]==PatientID):
      # 同一次透析
      if(data['start-analysis-date'][i] == start_dialysis):
        s_list.append([i, data['label_'+criteria][i]]) # 增加紀錄

      # 該次透析讀取完畢，開始分類(positive / negative)以及紀錄index(包含random)
      else:
        s_list = np.array(s_list)
        # 若為positive
        if True in s_list.swapaxes(1,0)[1]:
          if(s_list[list(s_list.swapaxes(1,0)[1]).index(True)][0] - s_list[0][0] <= 3):
            positive.append([s_list[0][0], s_list[list(s_list.swapaxes(1,0)[1]).index(True)][0], 1]) # 回傳第一個True的index (0, 第一次label=True的紀錄), 最多四個
        # 若為negative
        else:
          random_index = random.randint(s_list[0][0], s_list[len(s_list) - 1][0])
          negative.append([s_list[0][0], min(random_index, s_list[0][0]+3), 0]) # 回傳(0, random取紀錄次數), 最多四個

        # 初始化參數
        start_dialysis = data['start-analysis-date'][i]
        s_list = [[i, data['label_'+criteria][i]]]

    # 不同病人
    else:
      # 把正負樣本各取五個塞進去training_list裡面
      for j in positive:
        unbalanced_training_list.append(j)

      for j in negative:
        unbalanced_training_list.append(j)

      if(len(positive) <= 5): # 若正樣本 <= 五個，直接塞進去
        for j in positive:
          training_list.append(j)
      else:          # 若正樣本多於五個，random選5個
        for j in random.sample(range(len(positive)), 5):
          training_list.append(positive[j])

      if(len(negative) <= 5): # 若負樣本 <= 五個，直接塞進去
        for j in negative:
          training_list.append(j)
      else:          # 若負樣本多於五個，random選5個
        for j in random.sample(range(len(negative)), 5):
          training_list.append(negative[j])

      #初始化參數
      PatientID = data['ID'][i]
      positive = []
      negative = []
      s_list = [[i, data['label_'+criteria][i]]]
      start_dialysis = data['start-analysis-date'][i]

  # 把最後一位病人的也丟進去
  for j in positive:
    unbalanced_training_list.append(j)

  for j in negative:
    unbalanced_training_list.append(j)

  if(len(positive) <= 5): # 若正樣本 <= 五個，直接塞進去
    for j in positive:
      training_list.append(j)
  else:          # 若正樣本多於五個，random選5個
    for j in random.sample(range(len(positive)), 5):
      training_list.append(positive[j])

  if(len(negative) <= 5): # 若負樣本 <= 五個，直接塞進去
    for j in negative:
      training_list.append(j)
  else:          # 若負樣本多於五個，random選5個
    for j in random.sample(range(len(negative)), 5):
      training_list.append(negative[j])
  return sorted(unbalanced_training_list), sorted(training_list)

"""# 拿train, validation, test的row index"""

if(split_data):
  train_data = data[data["ID"].isin(train_PatientID)].reset_index(drop=True)
  unbalanced_train_list, train_list = get_data(train_data)
  valid_data = data[data["ID"].isin(valid_PatientID)].reset_index(drop=True)
  unbalanced_valid_list, valid_list = get_data(valid_data)
  test_data = data[data["ID"].isin(test_PatientID)].reset_index(drop=True)
  unbalanced_test_list, test_list = get_data(test_data)


  # record the patient_id
  #path = '/content/drive/My Drive/IDH_Thesis/20220729/split/20230323row_index_'+criteria+'.txt'

  path = data_row_index_path
  f = open(path, 'w')
  f.write('train_list = ')
  f.write(str(train_list))
  f.write('\n')

  f.write('valid_list = ')
  f.write(str(valid_list))
  f.write('\n')

  f.write('test_list = ')
  f.write(str(test_list))
  f.write('\n')
  f.close()

"""# 從 row_index.txt 直接讀 Train_list, Valid_list, Test_list"""

if(split_data==0):
  train_data = data[data["ID"].isin(train_PatientID)].reset_index(drop=True)
  valid_data = data[data["ID"].isin(valid_PatientID)].reset_index(drop=True)
  test_data = data[data["ID"].isin(test_PatientID)].reset_index(drop=True)

  f = open(data_row_index_path, "r")
  text = f.readlines()
  for i in range(3):
    info = str(text[i]).strip("\n").strip("'")
    exec(info)

"""# 產生Data"""

def generate_pickle(train_data, train_list, type_name):
  label = []
  sequential_list = []
  non_sequential_list = []
  time_step = []
  temperature_list = []
  for i in train_list:
    label.append(i[2])
    temp = list(train_data[non_sequential][i[0]:i[0]+1].values[0])
    temp = [-1 if math.isnan(x) else x for x in temp]
    non_sequential_list.append(temp)

    temp = list(train_data[temperature][i[0]:i[0]+1].values[0])
    temp = [-1 if math.isnan(x) else x for x in temp]
    temperature_list.append(temp)
    temp1 = []
    #temp2 = []
    temp3 = []
    for j in range(i[0], i[1]+1):
      temp = list(train_data[sequential][j:j+1].values[0])
      temp = [-1 if math.isnan(x) else x for x in temp]
      temp1.append(temp)
      #temp2.append(list(train_data[non_sequential][j:j+1].values[0]))
      temp3.append(train_data['time_step'][j:j+1].values[0])
    #print(len(temp2))
    sequential_list.append(temp1)
    time_step.append(temp3)
  traindata = []

  traindata.append(sequential_list)
  traindata.append(label)
  traindata.append(non_sequential_list)
  traindata.append(time_step)
  traindata.append(temperature_list)
  f = open(type_name + '_file.pickle','wb')
  pickle.dump(traindata,f)

train_data['time_step'][0:1].values[0]

import pickle
import math
# generate_pickle(train_data, train_list, '/content/drive/My Drive/IDH_Thesis/Training Data/label_data_'+criteria+'/train')
# generate_pickle(valid_data, valid_list, '/content/drive/My Drive/IDH_Thesis/Training Data/label_data_'+criteria+'/valid')
# generate_pickle(test_data, test_list, '/content/drive/My Drive/IDH_Thesis/Training Data/label_data_'+criteria+'/test')

generate_pickle(train_data, train_list, pickle_path+'train')
generate_pickle(valid_data, valid_list, pickle_path+'valid')
generate_pickle(test_data, test_list, pickle_path+'test')
print('Generate Pickle Successfully.')